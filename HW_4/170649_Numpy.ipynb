{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLDisQ6gAaMQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pwyZu2ibAhO1",
    "outputId": "01503b88-86a2-4619-d029-6ba8a7632cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "def loadIrisData():\n",
    "    iris = load_iris()\n",
    "    X=iris['data']\n",
    "    t=iris['target']\n",
    "    print(X.shape)\n",
    "    print(t.shape)\n",
    "    return X, t\n",
    "if __name__==\"__main__\":\n",
    "    loadIrisData();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48_5__HzBks_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(t_indices, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        t_indices: list of indices\n",
    "        N: total no. of classes\n",
    "    '''\n",
    "    assert N>max(t_indices), (N, max(t_indices))\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    t_indices = np.array(t_indices)\n",
    "    t_1hot = np.zeros((t_indices.size, N))\n",
    "    t_1hot[np.arange(t_indices.size), t_indices[np.arange(t_indices.size)]] = 1\n",
    "    return t_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2DsnXa89lIk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_one_hot_encoding():\n",
    "    t_1hot = one_hot_encoding([0,2], 3)\n",
    "    t_1hotTrue = np.array([[1.,0.,0.], [0.,0.,1.]])\n",
    "    assert np.all(np.isclose( t_1hot, t_1hotTrue ))\n",
    "    print('Test passed', '\\U0001F44D')\n",
    "if __name__==\"__main__\":\n",
    "    test_one_hot_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXxxA2YkB_I8"
   },
   "outputs": [],
   "source": [
    "def splitData(X,t,testFraction=0.2):\n",
    "    \"\"\"\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: np array of shape (Nsamples, dim)\n",
    "        t: np array of len Nsamples; can be one hot vectors or labels\n",
    "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
    "    \"\"\"\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    X = np.array(X)\n",
    "    t = np.array(t)\n",
    "    ind = np.arange(t.shape[0])\n",
    "    np.random.shuffle(ind)\n",
    "    X = X[ind]\n",
    "    t = t[ind]\n",
    "    testsize = int(testFraction*t.shape[0])\n",
    "    X_test = X[0:testsize]\n",
    "    t_test = t[0:testsize]\n",
    "    X_train = X[testsize:]\n",
    "    t_train = t[testsize:]\n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_splitData():\n",
    "    X = np.random.random((5,2))\n",
    "    t1hot = one_hot_encoding([1,0,2,1,2],3)\n",
    "    X_train, t1hot_train, X_test, t1hot_test = splitData(X,t1hot,.2)\n",
    "    assert X_train.shape==(4,2), [\"X_train.shape\", X_train.shape]\n",
    "    assert X_test.shape==(1,2), [\"X_test.shape\", X_test.shape]\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK2lZ6ZpCjAg"
   },
   "outputs": [],
   "source": [
    "### Normalize data to be of zero mean and unit variance\n",
    "def normalizeX(X_train, X_test):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train: np array 2d\n",
    "        X_test: np array 2d\n",
    "    Outputs:\n",
    "        Normalized np arrays 2d\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    X_train = np.array(X_train).astype(float)\n",
    "    X_test = np.array(X_test).astype(float)\n",
    "    X_test_normalized=np.copy(X_test)\n",
    "    X_train_normalized=np.copy(X_train)\n",
    "    \n",
    "    for i in np.arange(X_train.shape[1]):\n",
    "        X_test_normalized[:,i] = (X_test[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "        X_train_normalized[:,i] = (X_train[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "\n",
    "    return X_train_normalized, X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_normalizeX():\n",
    "    X_train = np.array([[1,1,0],[2,2,1]])\n",
    "    X_test = np.array([[1,1,0],[3,3,2]])\n",
    "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
    "    a = np.array([[-1.,-1.,-1.], [ 1., 1., 1.]])\n",
    "    b = np.array([[-1.,-1.,-1.], [ 3., 3., 3.]])\n",
    "    assert np.all(np.isclose( X_train_normalized, a )), a\n",
    "    assert np.all(np.isclose( X_test_normalized, b )), b\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_normalizeX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ_OSEoQLEuc"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y = 1/(1+np.exp(-1*x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_sigmoid():\n",
    "    x = np.array([np.log(4),np.log(0.25),0])\n",
    "    y = sigmoid(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.8, 0.2, 0.5]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y = np.exp(x)\n",
    "    Den = np.sum(y)\n",
    "    y = y / Den\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_softmax():\n",
    "    x = np.array([np.log(2),np.log(7),0])\n",
    "    y = softmax(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.2, 0.7, 0.1]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwi4QwxlOAOR"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape; it is sigmoid layer's output\n",
    "    Output:\n",
    "        y: numpy array of same shape as x; it is the derivative of sigmoid\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y = x * (1 - x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        '''   \n",
    "        Input:\n",
    "            ni: int, size of input layer\n",
    "            nh: int, size of hidden layer\n",
    "            no: int, size of output layer\n",
    "        Action:\n",
    "            Creates instance variables\n",
    "        NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
    "        '''\n",
    "        self.ni = ni\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "        return\n",
    "    \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Action:\n",
    "            Randomly initialize weights1 and weights2 with proper size random np arrays\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "        self.weights1 = np.random.uniform(-1, 1, (self.nh,self.ni+1))\n",
    "        self.weights2 = np.random.uniform(-1, 1, (self.no,self.nh+1))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        return v2\n",
    "\n",
    "    def backprop(self,x1,y1,eta):\n",
    "        '''\n",
    "        # application of the chain rule to find derivative of the categorical cross entropy loss function with respect to weights2 and weights1\n",
    "        Input:\n",
    "            x: numpy array of shape (ni,1)\n",
    "            y: numpy array of shape (no,1)\n",
    "            eta: learning rate\n",
    "        Action:\n",
    "            # Finding the derivatives\n",
    "            del_weights2: np array that stores the derivative of the loss function with respect to weights2\n",
    "            del_weights1: np array that stores the derivative of the loss function with respect to weights1\n",
    "\n",
    "            # Update the weights with the derivative of the categorical cross entropy loss function\n",
    "              weights1 += eta*del_weights1\n",
    "              weights2 += eta*del_weights2\n",
    "        ''' \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        x = np.reshape(np.array(x1), (np.array(x1).shape[0],1))\n",
    "        y = np.reshape(np.array(y1), (np.array(y1).shape[0],1))\n",
    "        \n",
    "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1 @ x\n",
    "        v1o = sigmoid(h1)\n",
    "        v1 = np.insert(v1o,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2 @ v1\n",
    "        v2 = softmax(h2)\n",
    "        \n",
    "        del_weights2 = (v2 - y) @ v1.T\n",
    "        \n",
    "        ind = np.arange(self.weights1.shape[0])\n",
    "        v = np.identity(self.weights1.shape[0])\n",
    "        for i in np.arange(self.weights1.shape[0]):\n",
    "            v[i, i] = v1o[i,0]*(1-v1o[i,0])\n",
    "        \n",
    "        \n",
    "        del_weights1 = v @ self.weights2.T[1:] @ (v2 - y) @ x.T\n",
    "        \n",
    "        return del_weights1, del_weights2\n",
    "\n",
    "    def fit(self, X, t, eta, epochs):\n",
    "        '''\n",
    "        input:\n",
    "            X: training input data \n",
    "            t: training targets\n",
    "            eta: learning rate\n",
    "            epochs: number of epochs\n",
    "        Action:\n",
    "            train the weights\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        self.init_weights()\n",
    "        count = 0\n",
    "        sum_der1 = np.zeros(self.weights1.shape)\n",
    "        sum_der2 = np.zeros(self.weights2.shape)\n",
    "        for i in range(epochs):\n",
    "            for j in range(t.shape[0]):\n",
    "                count += 1\n",
    "                temp1, temp2 = self.backprop(X[j], t[j], eta)\n",
    "                sum_der1 += temp1\n",
    "                sum_der2 += temp2\n",
    "                if count==1:\n",
    "                    self.weights1 -= eta * sum_der1\n",
    "                    self.weights2 -= eta * sum_der2\n",
    "                    count = 0\n",
    "                    sum_der1 = sum_der1*0\n",
    "                    sum_der2 = sum_der2*0\n",
    "                \n",
    "        \n",
    "    def predict_label(self,x):    \n",
    "        '''\n",
    "        Output:\n",
    "            y: np array of index\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "        y = np.zeros((np.array(x).shape[0],1))\n",
    "        for ind in range(x.shape[0]):\n",
    "            y[ind] = np.argmax(self.predict(x[ind]))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fmR8F2JIFwqm",
    "outputId": "fa868689-92c8-4a43-882f-3321cde1a301"
   },
   "outputs": [],
   "source": [
    "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
    "#printing the confusion matrix\n",
    "def getCM(y,t):\n",
    "    '''\n",
    "    Inputs:\n",
    "        y: estimated labels np array (Nsample,1)\n",
    "        t: targets np array (Nsamples,1)\n",
    "    Outputs:\n",
    "        CM : np array of confusion matrix\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    CM = np.zeros((3,3))\n",
    "    acc_pred = 0\n",
    "    for i,j in zip(t,y):\n",
    "        CM[int(i),int(j)] += 1\n",
    "        if i==j:\n",
    "            acc_pred += 1\n",
    "    #print(\"Accuracy:\",acc_pred/t.shape[0])\n",
    "    #print(CM)\n",
    "    return CM\n",
    "    #return acc_pred/t.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "Use the above functions to carry out the experiment:\n",
    "- load iris data and prepare it for NN\n",
    "- split randomly into 20% test data\n",
    "- create a NN with 1 hidden layer\n",
    "- train the network with training data\n",
    "- Plot loss w.r.t. number of epochs\n",
    "- Print confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hewsBv12weZ2",
    "outputId": "52407420-e7e5-4ca6-952b-6448ffe4b101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[[15.  0.  0.]\n",
      " [ 0.  6.  0.]\n",
      " [ 0.  1.  8.]]\n"
     ]
    }
   ],
   "source": [
    "def experiment():\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 10 MARKS\n",
    "    X, t = loadIrisData()\n",
    "    X_train, t_train, X_test, t_test = splitData(X, t)\n",
    "    X_train, X_test = normalizeX(X_train, X_test)\n",
    "    t_train = one_hot_encoding(t_train, 3)\n",
    "    \n",
    "    NN = NeuralNetwork(4, 10, 3)\n",
    "    NN.fit(X_train, t_train, 0.1, 1000)\n",
    "    y = NN.predict_label(X_test)\n",
    "    print(getCM(y.T[0], t_test))\n",
    "        \n",
    "    #print(\"Average Accuracy over 10 iterations:\", acc_avg/1)\n",
    "if __name__==\"__main__\":\n",
    "    experiment()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BP_Iris.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
